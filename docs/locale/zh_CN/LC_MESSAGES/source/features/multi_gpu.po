# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022-2024, The Isaac Lab Project Developers.
# This file is distributed under the same license as the Isaac Lab package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2024.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Isaac Lab 1.0.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-07-04 11:04+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: Ziqi Fan <fanziqi614@gmail.com>\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Generated-By: Babel 2.15.0\n"

#: ../../source/features/multi_gpu.rst:2
msgid "Multi-GPU and Multi-Node Training"
msgstr "多GPU和多节点训练"

#: ../../source/features/multi_gpu.rst:6
msgid ""
"Isaac Lab supports multi-GPU and multi-node reinforcement learning. "
"Currently, this feature is only available for RL-Games and skrl libraries "
"workflows. We are working on extending this feature to other workflows."
msgstr ""
"Isaac Lab支持多GPU和多节点的强化学习。目前，此功能仅适用于RL-Games和skrl库工作流程。我们正在努力将此功能扩展到其他工作流程中。"

#: ../../source/features/multi_gpu.rst:12
msgid ""
"Multi-GPU and multi-node training is only supported on Linux. Windows "
"support is not available at this time. This is due to limitations of the "
"NCCL library on Windows."
msgstr "多GPU和多节点训练仅在Linux上受支持。目前不支持Windows。这是由于Windows上NCCL库的限制。"

#: ../../source/features/multi_gpu.rst:17
msgid "Multi-GPU Training"
msgstr "多GPU训练"

#: ../../source/features/multi_gpu.rst:19
msgid ""
"For complex reinforcement learning environments, it may be desirable to "
"scale up training across multiple GPUs. This is possible in Isaac Lab "
"through the use of the `PyTorch distributed "
"<https://pytorch.org/docs/stable/distributed.html>`_ framework."
msgstr ""
"对于复杂的强化学习环境，可能希望跨多个GPU扩展训练。在Isaac Lab中，通过使用 `PyTorch分布式 "
"<https://pytorch.org/docs/stable/distributed.html>`_ 框架可以实现这一点。"

#: ../../source/features/multi_gpu.rst:23
msgid ""
"The :meth:`torch.distributed` API is used to launch multiple processes of "
"training, where the number of processes must be equal to or less than the "
"number of GPUs available. Each process runs on a dedicated GPU and launches "
"its own instance of Isaac Sim and the Isaac Lab environment. Each process "
"collects its own rollouts during the training process and has its own copy "
"of the policy network. During training, gradients are aggregated across the "
"processes and broadcasted back to the process at the end of the epoch."
msgstr ""
":meth:`torch.distributed` "
"API用于启动多个训练进程，其中进程的数量必须等于或小于可用的GPU数量。每个进程在专用GPU上运行，并启动其自己的Isaac Sim和Isaac "
"Lab环境实例。在训练过程中，梯度在进程之间汇总，并在周期结束时广播回进程。"

#: ../../source/features/multi_gpu.rst:-1
msgid "Multi-GPU training paradigm"
msgstr "多GPU训练范式"

#: ../../source/features/multi_gpu.rst:42
msgid ""
"To train with multiple GPUs, use the following command, where "
"``--proc_per_node`` represents the number of available GPUs:"
msgstr "要使用多个GPU进行训练，请使用以下命令，其中 ``--proc_per_node`` 表示可用的GPU数量："

#: ../../source/features/multi_gpu.rst
msgid "rl_games"
msgstr "rl_games"

#: ../../source/features/multi_gpu.rst
msgid "skrl"
msgstr "skrl"

#: ../../source/features/multi_gpu.rst:63
msgid "Multi-Node Training"
msgstr "多节点训练"

#: ../../source/features/multi_gpu.rst:65
msgid ""
"To scale up training beyond multiple GPUs on a single machine, it is also "
"possible to train across multiple nodes. To train across multiple "
"nodes/machines, it is required to launch an individual process on each node."
msgstr "要在单台计算机上跨多个GPU扩展训练，还可以在多个节点上训练。要在多个节点/机器上训练，需要在每个节点上启动一个单独的进程。"

#: ../../source/features/multi_gpu.rst:68
msgid ""
"For the master node, use the following command, where ``--proc_per_node`` "
"represents the number of available GPUs, and ``--nnodes`` represents the "
"number of nodes:"
msgstr ""
"对于主节点，请使用以下命令，其中 ``--proc_per_node`` 表示可用的GPU数量， ``--nnodes`` 表示节点的数量："

#: ../../source/features/multi_gpu.rst:88
msgid ""
"Note that the port (``5555``) can be replaced with any other available port."
msgstr "注意，端口（ ``5555`` ）可以更换为任何其他可用端口。"

#: ../../source/features/multi_gpu.rst:90
msgid ""
"For non-master nodes, use the following command, replacing ``--node_rank`` "
"with the index of each machine:"
msgstr "对于非主节点，请使用以下命令，将 ``--node_rank`` 替换为每台机器的索引："

#: ../../source/features/multi_gpu.rst:109
msgid ""
"For more details on multi-node training with PyTorch, please visit the "
"`PyTorch documentation "
"<https://pytorch.org/tutorials/intermediate/ddp_series_multinode.html>`_."
msgstr ""
"有关使用PyTorch进行多节点训练的更多详细信息，请访问 `PyTorch文档 "
"<https://pytorch.org/tutorials/intermediate/ddp_series_multinode.html>`_ 。"

#: ../../source/features/multi_gpu.rst:114
msgid ""
"As mentioned in the PyTorch documentation, \"multi-node training is "
"bottlenecked by inter-node communication latencies\". When this latency is "
"high, it is possible multi-node training will perform worse than running on "
"a single node instance."
msgstr ""
"如PyTorch文档中所述， `` 多节点训练受到节点间通信延迟的瓶颈 `` 。当这种延迟较高时，多节点训练可能表现不如在单节点实例上运行。"
