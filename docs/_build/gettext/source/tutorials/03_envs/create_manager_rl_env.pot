# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022-2024, The Isaac Lab Project Developers.
# This file is distributed under the same license as the Isaac Lab package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Isaac Lab 1.0.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-07-04 11:04+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:5
msgid "Creating a Manager-Based RL Environment"
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:9
msgid "Having learnt how to create a base environment in :ref:`tutorial-create-manager-base-env`, we will now look at how to create a manager-based task environment for reinforcement learning."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:12
msgid "The base environment is designed as an sense-act environment where the agent can send commands to the environment and receive observations from the environment. This minimal interface is sufficient for many applications such as traditional motion planning and controls. However, many applications require a task-specification which often serves as the learning objective for the agent. For instance, in a navigation task, the agent may be required to reach a goal location. To this end, we use the :class:`envs.ManagerBasedRLEnv` class which extends the base environment to include a task specification."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:19
msgid "Similar to other components in Isaac Lab, instead of directly modifying the base class :class:`envs.ManagerBasedRLEnv`, we encourage users to simply implement a configuration :class:`envs.ManagerBasedRLEnvCfg` for their task environment. This practice allows us to separate the task specification from the environment implementation, making it easier to reuse components of the same environment for different tasks."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:24
msgid "In this tutorial, we will configure the cartpole environment using the :class:`envs.ManagerBasedRLEnvCfg` to create a manager-based task for balancing the pole upright. We will learn how to specify the task using reward terms, termination criteria, curriculum and commands."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:30
msgid "The Code"
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:32
msgid "For this tutorial, we use the cartpole environment defined in ``omni.isaac.lab_tasks.manager_based.classic.cartpole`` module."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:0
msgid "Code for cartpole_env_cfg.py"
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:42
msgid "The script for running the environment ``run_cartpole_rl_env.py`` is present in the ``isaaclab/source/standalone/tutorials/03_envs`` directory. The script is similar to the ``cartpole_base_env.py`` script in the previous tutorial, except that it uses the :class:`envs.ManagerBasedRLEnv` instead of the :class:`envs.ManagerBasedEnv`."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:0
msgid "Code for run_cartpole_rl_env.py"
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:57
msgid "The Code Explained"
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:59
msgid "We already went through parts of the above in the :ref:`tutorial-create-manager-base-env` tutorial to learn about how to specify the scene, observations, actions and events. Thus, in this tutorial, we will focus only on the RL components of the environment."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:63
msgid "In Isaac Lab, we provide various implementations of different terms in the :mod:`envs.mdp` module. We will use some of these terms in this tutorial, but users are free to define their own terms as well. These are usually placed in their task-specific sub-package (for instance, in :mod:`omni.isaac.lab_tasks.manager_based.classic.cartpole.mdp`)."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:70
msgid "Defining rewards"
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:72
msgid "The :class:`managers.RewardManager` is used to compute the reward terms for the agent. Similar to the other managers, its terms are configured using the :class:`managers.RewardTermCfg` class. The :class:`managers.RewardTermCfg` class specifies the function or callable class that computes the reward as well as the weighting associated with it. It also takes in dictionary of arguments, ``\"params\"`` that are passed to the reward function when it is called."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:78
msgid "For the cartpole task, we will use the following reward terms:"
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:80
msgid "**Alive Reward**: Encourage the agent to stay alive for as long as possible."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:81
msgid "**Terminating Reward**: Similarly penalize the agent for terminating."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:82
msgid "**Pole Angle Reward**: Encourage the agent to keep the pole at the desired upright position."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:83
msgid "**Cart Velocity Reward**: Encourage the agent to keep the cart velocity as small as possible."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:84
msgid "**Pole Velocity Reward**: Encourage the agent to keep the pole velocity as small as possible."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:91
msgid "Defining termination criteria"
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:93
msgid "Most learning tasks happen over a finite number of steps that we call an episode. For instance, in the cartpole task, we want the agent to balance the pole for as long as possible. However, if the agent reaches an unstable or unsafe state, we want to terminate the episode. On the other hand, if the agent is able to balance the pole for a long time, we want to terminate the episode and start a new one so that the agent can learn to balance the pole from a different starting configuration."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:99
msgid "The :class:`managers.TerminationsCfg` configures what constitutes for an episode to terminate. In this example, we want the task to terminate when either of the following conditions is met:"
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:102
msgid "**Episode Length** The episode length is greater than the defined max_episode_length"
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:103
msgid "**Cart out of bounds** The cart goes outside of the bounds [-3, 3]"
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:105
msgid "The flag :attr:`managers.TerminationsCfg.time_out` specifies whether the term is a time-out (truncation) term or terminated term. These are used to indicate the two types of terminations as described in `Gymnasium's documentation <https://gymnasium.farama.org/tutorials/gymnasium_basics/handling_time_limits/>`_."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:114
msgid "Defining commands"
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:116
msgid "For various goal-conditioned tasks, it is useful to specify the goals or commands for the agent. These are handled through the :class:`managers.CommandManager`. The command manager handles resampling and updating the commands at each step. It can also be used to provide the commands as an observation to the agent."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:120
msgid "For this simple task, we do not use any commands. This is specified by using a command term with the :class:`envs.mdp.NullCommandCfg` configuration. However, you can see an example of command definitions in the locomotion or manipulation tasks."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:129
msgid "Defining curriculum"
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:131
msgid "Often times when training a learning agent, it helps to start with a simple task and gradually increase the tasks's difficulty as the agent training progresses. This is the idea behind curriculum learning. In Isaac Lab, we provide a :class:`managers.CurriculumManager` class that can be used to define a curriculum for your environment."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:135
msgid "In this tutorial we don't implement a curriculum for simplicity, but you can see an example of a curriculum definition in the other locomotion or manipulation tasks. We use a simple pass-through curriculum to define a curriculum manager that does not modify the environment."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:144
msgid "Tying it all together"
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:146
msgid "With all the above components defined, we can now create the :class:`ManagerBasedRLEnvCfg` configuration for the cartpole environment. This is similar to the :class:`ManagerBasedEnvCfg` defined in :ref:`tutorial-create-manager-base-env`, only with the added RL components explained in the above sections."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:155
msgid "Running the simulation loop"
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:157
msgid "Coming back to the ``run_cartpole_rl_env.py`` script, the simulation loop is similar to the previous tutorial. The only difference is that we create an instance of :class:`envs.ManagerBasedRLEnv` instead of the :class:`envs.ManagerBasedEnv`. Consequently, now the :meth:`envs.ManagerBasedRLEnv.step` method returns additional signals such as the reward and termination status. The information dictionary also maintains logging of quantities such as the reward contribution from individual terms, the termination status of each term, the episode length etc."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:169
msgid "The Code Execution"
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:171
msgid "Similar to the previous tutorial, we can run the environment by executing the ``run_cartpole_rl_env.py`` script."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:178
msgid "This should open a similar simulation as in the previous tutorial. However, this time, the environment returns more signals that specify the reward and termination status. Additionally, the individual environments reset themselves when they terminate based on the termination criteria specified in the configuration."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:183
msgid "To stop the simulation, you can either close the window, or press ``Ctrl+C`` in the terminal where you started the simulation."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:186
msgid "In this tutorial, we learnt how to create a task environment for reinforcement learning. We do this by extending the base environment to include the rewards, terminations, commands and curriculum terms. We also learnt how to use the :class:`envs.ManagerBasedRLEnv` class to run the environment and receive various signals from it."
msgstr ""

#: ../../source/tutorials/03_envs/create_manager_rl_env.rst:191
msgid "While it is possible to manually create an instance of :class:`envs.ManagerBasedRLEnv` class for a desired task, this is not scalable as it requires specialized scripts for each task. Thus, we exploit the :meth:`gymnasium.make` function to create the environment with the gym interface. We will learn how to do this in the next tutorial."
msgstr ""
